<!DOCTYPE html>

<html lang="en" data-content_root="./">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Training &#8212; kraken  documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/basic.css?v=b08954a9" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css?v=27fed22d" />
    <link rel="stylesheet" type="text/css" href="_static/graphviz.css?v=4ae1632d" />
    <link rel="stylesheet" type="text/css" href="_static/custom.css?v=89a84cc7" />
    <script src="_static/documentation_options.js?v=5929fcd5"></script>
    <script src="_static/doctools.js?v=9bcbadda"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="canonical" href="kraken.re/ketos.html" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="kraken API" href="api.html" />
    <link rel="prev" title="Advanced Usage" href="advanced.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="training">
<span id="ketos"></span><h1>Training<a class="headerlink" href="#training" title="Link to this heading">¶</a></h1>
<p>This page describes the training utilities available through the <code class="docutils literal notranslate"><span class="pre">ketos</span></code>
command line utility in depth. For a gentle introduction on model training
please refer to the <a class="reference internal" href="training.html#training"><span class="std std-ref">tutorial</span></a>.</p>
<p>Thanks to the magic of <a class="reference external" href="ftp://ftp.idsia.ch/pub/juergen/icml2006.pdf">Connectionist Temporal Classification</a> prerequisites for creating a
new recognition model are quite modest. The basic requirement is a number of
text lines (<code class="docutils literal notranslate"><span class="pre">ground</span> <span class="pre">truth</span></code>) that correspond to line images and some time for
training.</p>
<section id="transcription">
<h2>Transcription<a class="headerlink" href="#transcription" title="Link to this heading">¶</a></h2>
<p>Transcription is done through local browser based HTML transcription
environments. These are created by the <code class="docutils literal notranslate"><span class="pre">ketos</span> <span class="pre">transcribe</span></code> command line util.
Its basic input is just a number of image files and an output path to write the
HTML file to:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>ketos<span class="w"> </span>transcribe<span class="w"> </span>-o<span class="w"> </span>output.html<span class="w"> </span>image_1.png<span class="w"> </span>image_2.png<span class="w"> </span>...
</pre></div>
</div>
<p>While it is possible to put multiple images into a single transcription
environment splitting into one-image-per-HTML will ease parallel transcription
by multiple people.</p>
<p>The above command reads in the image files, converts them to black and white,
tries to split them into line images, and puts an editable text field next to
the image in the HTML. There are a handful of option changing the output:</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>option</p></th>
<th class="head"><p>action</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>-d, –text-direction</p></td>
<td><p>Sets the principal text direction both for the segmenter and in the HTML. Can be one of horizontal-lr, horizontal-rl, vertical-lr, vertical-rl.</p></td>
</tr>
<tr class="row-odd"><td><p>–scale</p></td>
<td><p>A segmenter parameter giving an estimate of average line height. Usually it shouldn’t be set manually.</p></td>
</tr>
<tr class="row-even"><td><p>–bw / –orig</p></td>
<td><p>Disables binarization of input images. If color or grayscale training data is desired this option has to be set.</p></td>
</tr>
<tr class="row-odd"><td><p>-m, –maxcolseps</p></td>
<td><p>A segmenter parameter limiting the number of columns that can be found in the input image by setting the maximum number of column separators. Set to 0 to disable column detection.</p></td>
</tr>
<tr class="row-even"><td><p>-b, –black_colseps / -w, –white_colseps</p></td>
<td><p>A segmenter parameter selecting white or black column separators.</p></td>
</tr>
<tr class="row-odd"><td><p>-f, –font</p></td>
<td><p>The font family to use for rendering the text in the HTML.</p></td>
</tr>
<tr class="row-even"><td><p>-fs, –font-style</p></td>
<td><p>The font style to use in the HTML.</p></td>
</tr>
<tr class="row-odd"><td><p>-p, –prefill</p></td>
<td><p>A model to use for prefilling the transcription. (Optional)</p></td>
</tr>
<tr class="row-even"><td><p>-o, –output</p></td>
<td><p>Output HTML file.</p></td>
</tr>
</tbody>
</table>
<p>It is possible to use an existing model to prefill the transcription environments:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>ketos<span class="w"> </span>transcribe<span class="w"> </span>-p<span class="w"> </span>~/arabic.mlmodel<span class="w"> </span>-p<span class="w"> </span>output.html<span class="w"> </span>image_1.png<span class="w"> </span>image_2.png<span class="w"> </span>...
</pre></div>
</div>
<p>Transcription has to be diplomatic, i.e. contain the exact character sequence
in the line image, including original orthography. Some deviations, such as
consistently omitting vocalization in Arabic texts, is possible as long as they
are systematic and relatively minor.</p>
<p>After transcribing a number of lines the results have to be saved, either using
the <code class="docutils literal notranslate"><span class="pre">Download</span></code> button on the lower right or through the regular <code class="docutils literal notranslate"><span class="pre">Save</span> <span class="pre">Page</span>
<span class="pre">As</span></code> function of the browser. All the work done is contained directly in the
saved files and it is possible to save partially transcribed files and continue
work later.</p>
<p>Next the contents of the filled transcription environments have to be
extracted through the <code class="docutils literal notranslate"><span class="pre">ketos</span> <span class="pre">extract</span></code> command:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>ketos<span class="w"> </span>extract<span class="w"> </span>--output<span class="w"> </span>output_directory<span class="w"> </span>*.html
</pre></div>
</div>
<p>There are some options dealing with color images and text normalization:</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>option</p></th>
<th class="head"><p>action</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>-b, –binarize / –no-binarize</p></td>
<td><p>Binarizes color/grayscale images (default) or retains the original in the output.</p></td>
</tr>
<tr class="row-odd"><td><p>-u, –normalization</p></td>
<td><p>Normalizes text to one of the following Unicode normalization forms: NFD, NFKD, NFC, NFKC</p></td>
</tr>
<tr class="row-even"><td><p>-s, –normalize-whitespace / –no-normalize-whitespace</p></td>
<td><p>Normalizes whitespace in extracted text. There are several different Unicode <a class="reference external" href="https://en.wikipedia.org/wiki/Whitespace_character#Unicode">whitespace</a> characters that
are replaced by a standard space when not disabled.</p></td>
</tr>
<tr class="row-odd"><td><p>–reorder / –no-reorder</p></td>
<td><p>Tells ketos to reorder the code
point for each line into
left-to-right order. Unicode
code points are always in
reading order, e.g. the first
code point in an Arabic line
will be the rightmost
character. This option reorders
them into <code class="docutils literal notranslate"><span class="pre">display</span> <span class="pre">order</span></code>,
i.e. the first code point is
the leftmost, the second one
the next from the left and so
on. The <code class="docutils literal notranslate"><span class="pre">train</span></code> subcommand
does this automatically, so it
usually isn’t needed.</p></td>
</tr>
<tr class="row-even"><td><p>-r, –rotate / –no-rotate</p></td>
<td><p>Skips rotation of vertical lines.</p></td>
</tr>
<tr class="row-odd"><td><p>-o, –output</p></td>
<td><p>Output directory, defaults to <code class="docutils literal notranslate"><span class="pre">training</span></code></p></td>
</tr>
</tbody>
</table>
<p>The result will be a directory filled with line image text pairs <code class="docutils literal notranslate"><span class="pre">NNNNNN.png</span></code>
and <code class="docutils literal notranslate"><span class="pre">NNNNNN.gt.txt</span></code> and a <code class="docutils literal notranslate"><span class="pre">manifest.txt</span></code> containing a list of all extracted
lines.</p>
</section>
<section id="id1">
<h2>Training<a class="headerlink" href="#id1" title="Link to this heading">¶</a></h2>
<p>The training utility allows training of <a class="reference internal" href="vgsl.html#vgsl"><span class="std std-ref">VGSL</span></a> specified models
both from scratch and from existing models. Training data is in all cases just
a directory containing image-text file pairs as produced by the
<code class="docutils literal notranslate"><span class="pre">transcribe/extract</span></code> tools. Here are its command line options:</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>option</p></th>
<th class="head"><p>action</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>-p, –pad</p></td>
<td><p>Left and right padding around lines</p></td>
</tr>
<tr class="row-odd"><td><p>-o, –output</p></td>
<td><p>Output model file prefix. Defaults to model.</p></td>
</tr>
<tr class="row-even"><td><p>-s, –spec</p></td>
<td><p>VGSL spec of the network to train. CTC layer
will be added automatically. default:
[1,48,0,1 Cr3,3,32 Do0.1,2 Mp2,2 Cr3,3,64
Do0.1,2 Mp2,2 S1(1x12)1,3 Lbx100 Do]</p></td>
</tr>
<tr class="row-odd"><td><p>-a, –append</p></td>
<td><p>Removes layers before argument and then
appends spec. Only works when loading an
existing model</p></td>
</tr>
<tr class="row-even"><td><p>-i, –load</p></td>
<td><p>Load existing file to continue training</p></td>
</tr>
<tr class="row-odd"><td><p>-F, –savefreq</p></td>
<td><p>Model save frequency in epochs during
training</p></td>
</tr>
<tr class="row-even"><td><p>-R, –report</p></td>
<td><p>Report creation frequency in epochs</p></td>
</tr>
<tr class="row-odd"><td><p>-q, –quit</p></td>
<td><p>Stop condition for training. Set to <cite>early</cite>
for early stopping (default) or <cite>dumb</cite> for fixed
number of epochs.</p></td>
</tr>
<tr class="row-even"><td><p>-N, –epochs</p></td>
<td><p>Number of epochs to train for. Set to -1 for indefinite training.</p></td>
</tr>
<tr class="row-odd"><td><p>–lag</p></td>
<td><p>Number of epochs to wait before stopping
training without improvement. Only used when using early stopping.</p></td>
</tr>
<tr class="row-even"><td><p>–min-delta</p></td>
<td><p>Minimum improvement between epochs to reset
early stopping. Defaults to 0.005.</p></td>
</tr>
<tr class="row-odd"><td><p>-d, –device</p></td>
<td><p>Select device to use (cpu, cuda:0, cuda:1,…). GPU acceleration requires CUDA.</p></td>
</tr>
<tr class="row-even"><td><p>–optimizer</p></td>
<td><p>Select optimizer (Adam, SGD, RMSprop).</p></td>
</tr>
<tr class="row-odd"><td><p>-r, –lrate</p></td>
<td><p>Learning rate  [default: 0.001]</p></td>
</tr>
<tr class="row-even"><td><p>-m, –momentum</p></td>
<td><p>Momentum used with SGD optimizer. Ignored otherwise.</p></td>
</tr>
<tr class="row-odd"><td><p>-w, –weight-decay</p></td>
<td><p>Weight decay.</p></td>
</tr>
<tr class="row-even"><td><p>–schedule</p></td>
<td><p>Sets the learning rate scheduler. May be either constant or 1cycle. For 1cycle
the cycle length is determined by the <cite>–epoch</cite> option.</p></td>
</tr>
<tr class="row-odd"><td><p>-p, –partition</p></td>
<td><p>Ground truth data partition ratio between train/validation set</p></td>
</tr>
<tr class="row-even"><td><p>-u, –normalization</p></td>
<td><p>Ground truth Unicode normalization. One of NFC, NFKC, NFD, NFKD.</p></td>
</tr>
<tr class="row-odd"><td><p>-c, –codec</p></td>
<td><p>Load a codec JSON definition (invalid if loading existing model)</p></td>
</tr>
<tr class="row-even"><td><p>–resize</p></td>
<td><p>Codec/output layer resizing option. If set
to <cite>add</cite> code points will be added, <cite>both</cite>
will set the layer to match exactly the
training data, <cite>fail</cite> will abort if training
data and model codec do not match. Only valid when refining an existing model.</p></td>
</tr>
<tr class="row-odd"><td><p>-n, –reorder / –no-reorder</p></td>
<td><p>Reordering of code points to display order.</p></td>
</tr>
<tr class="row-even"><td><p>-t, –training-files</p></td>
<td><p>File(s) with additional paths to training data. Used to
enforce an explicit train/validation set split and deal with
training sets with more lines than the command line can process. Can be used more than once.</p></td>
</tr>
<tr class="row-odd"><td><p>-e, –evaluation-files</p></td>
<td><p>File(s) with paths to evaluation data. Overrides the <cite>-p</cite> parameter.</p></td>
</tr>
<tr class="row-even"><td><p>–preload / –no-preload</p></td>
<td><p>Hard enable/disable for training data preloading. Preloading
training data into memory is enabled per default for sets with less than 2500 lines.</p></td>
</tr>
<tr class="row-odd"><td><p>–threads</p></td>
<td><p>Number of OpenMP threads when running on CPU. Defaults to min(4, #cores).</p></td>
</tr>
</tbody>
</table>
<section id="from-scratch">
<h3>From Scratch<a class="headerlink" href="#from-scratch" title="Link to this heading">¶</a></h3>
<p>The absolut minimal example to train a new model is:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>ketos<span class="w"> </span>train<span class="w"> </span>training_data/*.png
</pre></div>
</div>
<p>Training will continue until the error does not improve anymore and the best
model (among intermediate results) will be saved in the current directory.</p>
<p>In some cases, such as color inputs, changing the network architecture might be
useful:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>ketos<span class="w"> </span>train<span class="w"> </span>-s<span class="w"> </span><span class="s1">&#39;[1,0,0,3 Cr3,3,16 Mp3,3 Lfys64 Lbx128 Lbx256 Do]&#39;</span><span class="w"> </span>syr/*.png
</pre></div>
</div>
<p>Complete documentation for the network description language can be found on the
<a class="reference internal" href="vgsl.html#vgsl"><span class="std std-ref">VGSL</span></a> page.</p>
<p>Sometimes the early stopping default parameters might produce suboptimal
results such as stopping training too soon. Adjusting the minimum delta an/or
lag can be useful:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>ketos<span class="w"> </span>train<span class="w"> </span>--lag<span class="w"> </span><span class="m">10</span><span class="w"> </span>--min-delta<span class="w"> </span><span class="m">0</span>.001<span class="w"> </span>syr/*.png
</pre></div>
</div>
<p>To switch optimizers from Adam to SGD or RMSprop just set the option:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>ketos<span class="w"> </span>train<span class="w"> </span>--optimizer<span class="w"> </span>SGD<span class="w"> </span>syr/*.png
</pre></div>
</div>
<p>It is possible to resume training from a previously saved model:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>ketos<span class="w"> </span>train<span class="w"> </span>-i<span class="w"> </span>model_25.mlmodel<span class="w"> </span>syr/*.png
</pre></div>
</div>
</section>
<section id="fine-tuning">
<h3>Fine Tuning<a class="headerlink" href="#fine-tuning" title="Link to this heading">¶</a></h3>
<p>Fine tuning an existing model for another typeface or new characters is also
possible with the same syntax as resuming regular training:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>ketos<span class="w"> </span>train<span class="w"> </span>-i<span class="w"> </span>model_best.mlmodel<span class="w"> </span>syr/*.png
</pre></div>
</div>
<p>The caveat is that the alphabet of the base model and training data have to be
an exact match. Otherwise an error will be raised:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>ketos<span class="w"> </span>train<span class="w"> </span>-i<span class="w"> </span>model_5.mlmodel<span class="w"> </span>--no-preload<span class="w"> </span>kamil/*.png
<span class="go">Building training set  [####################################]  100%</span>
<span class="go">Building validation set  [####################################]  100%</span>
<span class="go">[0.8616] alphabet mismatch {&#39;~&#39;, &#39;»&#39;, &#39;8&#39;, &#39;9&#39;, &#39;ـ&#39;}</span>
<span class="go">Network codec not compatible with training set</span>
<span class="go">[0.8620] Training data and model codec alphabets mismatch: {&#39;ٓ&#39;, &#39;؟&#39;, &#39;!&#39;, &#39;ص&#39;, &#39;،&#39;, &#39;ذ&#39;, &#39;ة&#39;, &#39;ي&#39;, &#39;و&#39;, &#39;ب&#39;, &#39;ز&#39;, &#39;ح&#39;, &#39;غ&#39;, &#39;~&#39;, &#39;ف&#39;, &#39;)&#39;, &#39;د&#39;, &#39;خ&#39;, &#39;م&#39;, &#39;»&#39;, &#39;ع&#39;, &#39;ى&#39;, &#39;ق&#39;, &#39;ش&#39;, &#39;ا&#39;, &#39;ه&#39;, &#39;ك&#39;, &#39;ج&#39;, &#39;ث&#39;, &#39;(&#39;, &#39;ت&#39;, &#39;ظ&#39;, &#39;ض&#39;, &#39;ل&#39;, &#39;ط&#39;, &#39;؛&#39;, &#39;ر&#39;, &#39;س&#39;, &#39;ن&#39;, &#39;ء&#39;, &#39;ٔ&#39;, &#39;«&#39;, &#39;ـ&#39;, &#39;ٕ&#39;}</span>
</pre></div>
</div>
<p>There are two modes dealing with mismatching alphabets, <code class="docutils literal notranslate"><span class="pre">add</span></code> and <code class="docutils literal notranslate"><span class="pre">both</span></code>.
<code class="docutils literal notranslate"><span class="pre">add</span></code> resizes the output layer and codec of the loaded model to include all
characters in the new training set without removing any characters. <code class="docutils literal notranslate"><span class="pre">both</span></code>
will make the resulting model an exact match with the new training set by both
removing unused characters from the model and adding new ones.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>ketos<span class="w"> </span>-v<span class="w"> </span>train<span class="w"> </span>--resize<span class="w"> </span>add<span class="w"> </span>-i<span class="w"> </span>model_5.mlmodel<span class="w"> </span>syr/*.png
<span class="go">...</span>
<span class="go">[0.7943] Training set 788 lines, validation set 88 lines, alphabet 50 symbols</span>
<span class="go">...</span>
<span class="go">[0.8337] Resizing codec to include 3 new code points</span>
<span class="go">[0.8374] Resizing last layer in network to 52 outputs</span>
<span class="go">...</span>
</pre></div>
</div>
<p>In this example 3 characters were added for a network that is able to
recognize 52 different characters after sufficient additional training.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>ketos<span class="w"> </span>-v<span class="w"> </span>train<span class="w"> </span>--resize<span class="w"> </span>both<span class="w"> </span>-i<span class="w"> </span>model_5.mlmodel<span class="w"> </span>syr/*.png
<span class="go">...</span>
<span class="go">[0.7593] Training set 788 lines, validation set 88 lines, alphabet 49 symbols</span>
<span class="go">...</span>
<span class="go">[0.7857] Resizing network or given codec to 49 code sequences</span>
<span class="go">[0.8344] Deleting 2 output classes from network (46 retained)</span>
<span class="go">...</span>
</pre></div>
</div>
<p>In <code class="docutils literal notranslate"><span class="pre">both</span></code> mode 2 of the original characters were removed and 3 new ones were added.</p>
</section>
<section id="slicing">
<h3>Slicing<a class="headerlink" href="#slicing" title="Link to this heading">¶</a></h3>
<p>Refining on mismatched alphabets has its limits. If the alphabets are highly
different the modification of the final linear layer to add/remove character
will destroy the inference capabilities of the network. In those cases it is
faster to slice off the last few layers of the network and only train those
instead of a complete network from scratch.</p>
<p>Taking the default network definition as printed in the debug log we can see
the layer indices of the model:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">[0.8760] Creating new model [1,48,0,1 Cr3,3,32 Do0.1,2 Mp2,2 Cr3,3,64 Do0.1,2 Mp2,2 S1(1x12)1,3 Lbx100 Do] with 48 outputs</span>
<span class="go">[0.8762] layer          type    params</span>
<span class="go">[0.8790] 0              conv    kernel 3 x 3 filters 32 activation r</span>
<span class="go">[0.8795] 1              dropout probability 0.1 dims 2</span>
<span class="go">[0.8797] 2              maxpool kernel 2 x 2 stride 2 x 2</span>
<span class="go">[0.8802] 3              conv    kernel 3 x 3 filters 64 activation r</span>
<span class="go">[0.8804] 4              dropout probability 0.1 dims 2</span>
<span class="go">[0.8806] 5              maxpool kernel 2 x 2 stride 2 x 2</span>
<span class="go">[0.8813] 6              reshape from 1 1 x 12 to 1/3</span>
<span class="go">[0.8876] 7              rnn     direction b transposed False summarize False out 100 legacy None</span>
<span class="go">[0.8878] 8              dropout probability 0.5 dims 1</span>
<span class="go">[0.8883] 9              linear  augmented False out 48</span>
</pre></div>
</div>
<p>To remove everything after the initial convolutional stack and add untrained
layers we define a network stub and index for appending:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>ketos<span class="w"> </span>train<span class="w"> </span>-i<span class="w"> </span>model_1.mlmodel<span class="w"> </span>--append<span class="w"> </span><span class="m">7</span><span class="w"> </span>-s<span class="w"> </span><span class="s1">&#39;[Lbx256 Do]&#39;</span><span class="w"> </span>syr/*.png
<span class="go">Building training set  [####################################]  100%</span>
<span class="go">Building validation set  [####################################]  100%</span>
<span class="go">[0.8014] alphabet mismatch {&#39;8&#39;, &#39;3&#39;, &#39;9&#39;, &#39;7&#39;, &#39;܇&#39;, &#39;݀&#39;, &#39;݂&#39;, &#39;4&#39;, &#39;:&#39;, &#39;0&#39;}</span>
<span class="go">Slicing and dicing model ✓</span>
</pre></div>
</div>
<p>The new model will behave exactly like a new one, except potentially training a
lot faster.</p>
</section>
</section>
<section id="testing">
<h2>Testing<a class="headerlink" href="#testing" title="Link to this heading">¶</a></h2>
<p>Picking a particular model from a pool or getting a more detailled look on the
recognition accuracy can be done with the <cite>test</cite> command. It uses transcribed
lines, the test set, in the same format as the <cite>train</cite> command, recognizes the
line images with one or more models, and creates a detailled report of the
differences from the ground truth for each of them.</p>
<dl class="option-list">
<dt><kbd><span class="option">-m</span>, <span class="option">--model</span></kbd></dt>
<dd><p>Model(s) to evaluate.</p>
</dd>
<dt><kbd><span class="option">-e</span>, <span class="option">--evaluation-files</span></kbd></dt>
<dd><p>File(s) with paths to evaluation data.</p>
</dd>
<dt><kbd><span class="option">-d</span>, <span class="option">--device</span></kbd></dt>
<dd><p>Select device to use.</p>
</dd>
<dt><kbd><span class="option">-p</span>, <span class="option">--pad</span></kbd></dt>
<dd><p>Left and right padding around lines.</p>
</dd>
</dl>
<p>Transcriptions are handed to the command in the same way as for the <cite>train</cite>
command, either through a manifest with <cite>-e/–evaluation-files</cite> or by just
adding a number of image files as the final argument:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>ketos<span class="w"> </span><span class="nb">test</span><span class="w"> </span>-m<span class="w"> </span><span class="nv">$model</span><span class="w"> </span>-e<span class="w"> </span>test.txt<span class="w"> </span>test/*.png
<span class="go">Evaluating $model</span>
<span class="go">Evaluating  [####################################]  100%</span>
<span class="go">=== report test_model.mlmodel ===</span>

<span class="go">7012 Characters</span>
<span class="go">6022 Errors</span>
<span class="go">14.12%       Accuracy</span>

<span class="go">5226 Insertions</span>
<span class="go">2    Deletions</span>
<span class="go">794  Substitutions</span>

<span class="go">Count Missed   %Right</span>
<span class="go">1567  575    63.31%  Common</span>
<span class="go">5230  5230   0.00%   Arabic</span>
<span class="go">215   215    0.00%   Inherited</span>

<span class="go">Errors       Correct-Generated</span>
<span class="go">773  { ا } - {  }</span>
<span class="go">536  { ل } - {  }</span>
<span class="go">328  { و } - {  }</span>
<span class="go">274  { ي } - {  }</span>
<span class="go">266  { م } - {  }</span>
<span class="go">256  { ب } - {  }</span>
<span class="go">246  { ن } - {  }</span>
<span class="go">241  { SPACE } - {  }</span>
<span class="go">207  { ر } - {  }</span>
<span class="go">199  { ف } - {  }</span>
<span class="go">192  { ه } - {  }</span>
<span class="go">174  { ع } - {  }</span>
<span class="go">172  { ARABIC HAMZA ABOVE } - {  }</span>
<span class="go">144  { ت } - {  }</span>
<span class="go">136  { ق } - {  }</span>
<span class="go">122  { س } - {  }</span>
<span class="go">108  { ، } - {  }</span>
<span class="go">106  { د } - {  }</span>
<span class="go">82   { ك } - {  }</span>
<span class="go">81   { ح } - {  }</span>
<span class="go">71   { ج } - {  }</span>
<span class="go">66   { خ } - {  }</span>
<span class="go">62   { ة } - {  }</span>
<span class="go">60   { ص } - {  }</span>
<span class="go">39   { ، } - { - }</span>
<span class="go">38   { ش } - {  }</span>
<span class="go">30   { ا } - { - }</span>
<span class="go">30   { ن } - { - }</span>
<span class="go">29   { ى } - {  }</span>
<span class="go">28   { ذ } - {  }</span>
<span class="go">27   { ه } - { - }</span>
<span class="go">27   { ARABIC HAMZA BELOW } - {  }</span>
<span class="go">25   { ز } - {  }</span>
<span class="go">23   { ث } - {  }</span>
<span class="go">22   { غ } - {  }</span>
<span class="go">20   { م } - { - }</span>
<span class="go">20   { ي } - { - }</span>
<span class="go">20   { ) } - {  }</span>
<span class="go">19   { : } - {  }</span>
<span class="go">19   { ط } - {  }</span>
<span class="go">19   { ل } - { - }</span>
<span class="go">18   { ، } - { . }</span>
<span class="go">17   { ة } - { - }</span>
<span class="go">16   { ض } - {  }</span>
<span class="go">...</span>
<span class="go">Average accuracy: 14.12%, (stddev: 0.00)</span>
</pre></div>
</div>
<p>The report(s) contains character accuracy measured per script and a detailled
list of confusions. When evaluating multiple models the last line of the output
will the average accuracy and the standard deviation across all of them.</p>
</section>
<section id="artificial-training-data">
<h2>Artificial Training Data<a class="headerlink" href="#artificial-training-data" title="Link to this heading">¶</a></h2>
<p>It is possible to rely on artificially created training data, instead of
laborously creating ground truth by manual means. A proper typeface and some
text in the target language will be needed.</p>
<p>For many popular historical fonts there are free reproductions which quite
closely match printed editions. Most are available in your distribution’s</p>
<p>repositories and often shipped with TeX Live.</p>
<p>Some good places to start for non-Latin scripts are:</p>
<ul class="simple">
<li><p><a class="reference external" href="http://www.amirifont.org/">Amiri</a>, a classical Arabic typeface by Khaled
Hosny</p></li>
<li><p>The <a class="reference external" href="http://www.greekfontsociety.gr/">Greek Font Society</a> offers freely
licensed (historical) typefaces for polytonic Greek.</p></li>
<li><p>The friendly religious fanatics from <a class="reference external" href="http://scripts.sil.org/">SIL</a>
assemble a wide variety of fonts for non-Latin scripts.</p></li>
</ul>
<p>Next we need some text to generate artificial line images from. It should be a
typical example of the type of printed works you want to recognize and at least
500-1000 lines in length.</p>
<p>A minimal invocation to the line generation tool will look like this:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>ketos<span class="w"> </span>linegen<span class="w"> </span>-f<span class="w"> </span>Amiri<span class="w"> </span>da1.txt<span class="w"> </span>da2.txt
<span class="go">Reading texts   ✓</span>
<span class="go">Read 3692 unique lines</span>
<span class="go">Σ (len: 99)</span>
<span class="go">Symbols:  !(),-./0123456789:ABEFGHILMNPRS[]_acdefghiklmnoprstuvyz«»،؟ءآأؤإئابةتثجحخدذرزسشصضطظعغـفقكلمنهوىيپ</span>
<span class="go">Writing images  ✓</span>
</pre></div>
</div>
<p>The output will be written to a directory called <code class="docutils literal notranslate"><span class="pre">training_data</span></code>, although
this may be changed using the <code class="docutils literal notranslate"><span class="pre">-o</span></code> option. Each text line is rendered using
the Amiri typeface.</p>
<section id="alphabet-and-normalization">
<h3>Alphabet and Normalization<a class="headerlink" href="#alphabet-and-normalization" title="Link to this heading">¶</a></h3>
<p>Let’s take a look at important information in the preamble:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">Read 3692 unique lines</span>
<span class="go">Σ (len: 99)</span>
<span class="go">Symbols:  !(),-./0123456789:ABEFGHILMNPRS[]_acdefghiklmnoprstuvyz«»،؟ﺀﺁﺃﺅﺈﺋﺎﺑﺔﺘﺜﺠﺤﺧﺩﺫﺭﺰﺴﺸﺼﻀﻄﻈﻌﻐـﻔﻘﻜﻠﻤﻨﻫﻭﻰﻳپ</span>
</pre></div>
</div>
<p>ketos tells us that it found 3692 unique lines which contained 99 different
<code class="docutils literal notranslate"><span class="pre">symbols</span></code> or <code class="docutils literal notranslate"><span class="pre">code</span> <span class="pre">points</span></code>.  We can see the training data contains all of
the Arabic script including accented precomposed characters, but only a subset
of Latin characters, numerals, and punctuation. A trained model will be able to
recognize only these exact symbols, e.g. a <code class="docutils literal notranslate"><span class="pre">C</span></code> or <code class="docutils literal notranslate"><span class="pre">j</span></code> on the page will
never be recognized. Either accept this limitation or add additional text lines
to the training corpus until the alphabet matches your needs.</p>
<p>We can also force a normalization form using the <code class="docutils literal notranslate"><span class="pre">-u</span></code> option; per default
none is applied. For example:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>ketos<span class="w"> </span>linegen<span class="w"> </span>-u<span class="w"> </span>NFD<span class="w"> </span>-f<span class="w"> </span><span class="s2">&quot;GFS Philostratos&quot;</span><span class="w"> </span>grc.txt
<span class="go">Reading texts   ✓</span>
<span class="go">Read 2860 unique lines</span>
<span class="go">Σ (len: 132)</span>
<span class="go">Symbols:  #&amp;&#39;()*,-./0123456789:;ABCDEGHILMNOPQRSTVWXZ]abcdefghiklmnopqrstuvxy §·ΑΒΓΔΕΖΗΘΙΚΛΜΝΞΟΠΡΣΤΥΦΧΨΩαβγδεζηθικλμνξοπρςστυφχψω—‘’“</span>
<span class="go">Combining Characters: COMBINING GRAVE ACCENT, COMBINING ACUTE ACCENT, COMBINING DIAERESIS, COMBINING COMMA ABOVE, COMBINING REVERSED COMMA ABOVE, COMBINING DOT BELOW, COMBINING GREEK PERISPOMENI, COMBINING GREEK YPOGEGRAMMENI</span>


<span class="gp">$ </span>ketos<span class="w"> </span>linegen<span class="w"> </span>-u<span class="w"> </span>NFC<span class="w"> </span>-f<span class="w"> </span><span class="s2">&quot;GFS Philostratos&quot;</span><span class="w"> </span>grc.txt
<span class="go">Reading texts   ✓</span>
<span class="go">Read 2860 unique lines</span>
<span class="go">Σ (len: 231)</span>
<span class="go">Symbols:  #&amp;&#39;()*,-./0123456789:;ABCDEGHILMNOPQRSTVWXZ]abcdefghiklmnopqrstuvxy §·ΐΑΒΓΔΕΖΘΙΚΛΜΝΞΟΠΡΣΤΦΧΨΩάέήίαβγδεζηθικλμνξοπρςστυφχψωϊϋόύώἀἁἂἃἄἅἈἌἎἐἑἓἔἕἘἙἜἝἠἡἢἣἤἥἦἧἩἭἮἰἱἳἴἵἶἷἸἹἼὀὁὂὃὄὅὈὉὌὐὑὓὔὕὖὗὙὝὠὡὢὤὥὦὧὨὩὰὲὴὶὸὺὼᾄᾐᾑᾔᾗᾠᾤᾧᾳᾶᾷῃῄῆῇῒῖῥῦῬῳῴῶῷ—‘’“</span>
<span class="go">Combining Characters: COMBINING ACUTE ACCENT, COMBINING DOT BELOW</span>
</pre></div>
</div>
<p>While there hasn’t been any study on the effect of different normalizations on
recognition accuracy there are some benefits to NFD, namely decreased model
size and easier validation of the alphabet.</p>
</section>
<section id="other-parameters">
<h3>Other Parameters<a class="headerlink" href="#other-parameters" title="Link to this heading">¶</a></h3>
<p>Sometimes it is desirable to draw a certain number of lines randomly from one
or more large texts. The <code class="docutils literal notranslate"><span class="pre">-n</span></code> option does just that:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>ketos<span class="w"> </span>linegen<span class="w"> </span>-u<span class="w"> </span>NFD<span class="w"> </span>-n<span class="w"> </span><span class="m">100</span><span class="w"> </span>-f<span class="w"> </span>Amiri<span class="w"> </span>da1.txt<span class="w"> </span>da2.txt<span class="w"> </span>da3.txt<span class="w"> </span>da4.txt
<span class="go">Reading texts   ✓</span>
<span class="go">Read 114265 unique lines</span>
<span class="go">Sampling 100 lines      ✓</span>
<span class="go">Σ (len: 64)</span>
<span class="go">Symbols:  !(),-./0123456789:[]{}«»،؛؟ءابةتثجحخدذرزسشصضطظعغـفقكلمنهوىي–</span>
<span class="go">Combining Characters: ARABIC MADDAH ABOVE, ARABIC HAMZA ABOVE, ARABIC HAMZA BELOW</span>
<span class="go">Writing images ⢿</span>
</pre></div>
</div>
<p>It is also possible to adjust to amount of degradation/distortion of line
images by using the <code class="docutils literal notranslate"><span class="pre">-s/-r/-d/-ds</span></code> switches:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>ketos<span class="w"> </span>linegen<span class="w"> </span>-m<span class="w"> </span><span class="m">0</span>.2<span class="w"> </span>-s<span class="w"> </span><span class="m">0</span>.002<span class="w"> </span>-r<span class="w"> </span><span class="m">0</span>.001<span class="w"> </span>-d<span class="w"> </span><span class="m">3</span><span class="w"> </span>Downloads/D/A/da1.txt
<span class="go">Reading texts   ✓</span>
<span class="go">Read 859 unique lines</span>
<span class="go">Σ (len: 46)</span>
<span class="go">Symbols:  !&quot;-.:،؛؟ءآأؤإئابةتثجحخدذرزسشصضطظعغفقكلمنهوىي﻿</span>
<span class="go">Writing images  ⣽</span>
</pre></div>
</div>
<p>Sometimes the shaping engine misbehaves using some fonts (notably <code class="docutils literal notranslate"><span class="pre">GFS</span>
<span class="pre">Philostratos</span></code>) by rendering texts in certain normalizations incorrectly if the
font does not contain glyphs for decomposed characters. One sign are misplaced
diacritics and glyphs in different fonts. A workaround is renormalizing the
text for rendering purposes (here to NFC):</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>ketos<span class="w"> </span>linegen<span class="w"> </span>-ur<span class="w"> </span>NFC<span class="w"> </span>-u<span class="w"> </span>NFD<span class="w"> </span>-f<span class="w"> </span><span class="s2">&quot;GFS Philostratos&quot;</span><span class="w"> </span>grc.txt
</pre></div>
</div>
</section>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="index.html">
              <img class="logo" src="_static/kraken.png" alt="Logo of kraken"/>
            </a></p>
  <div>
    <h3><a href="index.html">Table of Contents</a></h3>
    <ul>
<li><a class="reference internal" href="#">Training</a><ul>
<li><a class="reference internal" href="#transcription">Transcription</a></li>
<li><a class="reference internal" href="#id1">Training</a><ul>
<li><a class="reference internal" href="#from-scratch">From Scratch</a></li>
<li><a class="reference internal" href="#fine-tuning">Fine Tuning</a></li>
<li><a class="reference internal" href="#slicing">Slicing</a></li>
</ul>
</li>
<li><a class="reference internal" href="#testing">Testing</a></li>
<li><a class="reference internal" href="#artificial-training-data">Artificial Training Data</a><ul>
<li><a class="reference internal" href="#alphabet-and-normalization">Alphabet and Normalization</a></li>
<li><a class="reference internal" href="#other-parameters">Other Parameters</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  </div><div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="advanced.html" title="previous chapter">Advanced Usage</a></li>
      <li>Next: <a href="api.html" title="next chapter">kraken API</a></li>
  </ul></li>
</ul>
</div>
<search id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script>
<h3>Versions</h3>
<ul>
  <li><a href="ketos.html">2.0.0</a></li>
  <li><a href="../3.0/ketos.html">3.0</a></li>
  <li><a href="../4.0/ketos.html">4.0</a></li>
  <li><a href="../4.1/ketos.html">4.1</a></li>
  <li><a href="../4.2.0/ketos.html">4.2.0</a></li>
  <li><a href="../4.3.0/ketos.html">4.3.0</a></li>
  <li><a href="../5.0.0/ketos.html">5.0.0</a></li>
  <li><a href="../5.1/ketos.html">5.1</a></li>
  <li><a href="../5.2/ketos.html">5.2</a></li>
  <li><a href="../5.3.0/ketos.html">5.3.0</a></li>
  <li><a href="../6.0.0/index.html">6.0.0</a></li>
</ul>


        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2015-2026, Benjamin Kiessling.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 8.2.3</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 1.0.0</a>
      
      |
      <a href="_sources/ketos.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>